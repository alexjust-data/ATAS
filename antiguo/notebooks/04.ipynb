{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a290879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel_ingestion.py\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def parse_excel_file(filepath: Path) -> dict:\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    required_sheets = [\"Journal\", \"Executions\", \"Statistics\"]\n",
    "    for sheet in required_sheets:\n",
    "        if sheet not in xls.sheet_names:\n",
    "            raise ValueError(f\"El archivo {filepath.name} no contiene la hoja '{sheet}'\")\n",
    "    \n",
    "    return {\n",
    "        \"source_file\": filepath.name,\n",
    "        \"journal\": pd.read_excel(xls, sheet_name=\"Journal\"),\n",
    "        \"executions\": pd.read_excel(xls, sheet_name=\"Executions\"),\n",
    "        \"statistics\": pd.read_excel(xls, sheet_name=\"Statistics\")\n",
    "    }\n",
    "\n",
    "\n",
    "# process_trades.py\n",
    "import pandas as pd\n",
    "\n",
    "def build_trade_dataframe(journal_df, executions_df, source_file, capital_base=600):\n",
    "    n_trades = len(journal_df)\n",
    "    n_execs = len(executions_df)\n",
    "    if n_execs < 2:\n",
    "        raise ValueError(\"No hay suficientes ejecuciones.\")\n",
    "\n",
    "    max_trades = min(n_trades, n_execs // 2)\n",
    "    trades_df = journal_df.iloc[:max_trades].copy()\n",
    "\n",
    "    trades_df = trades_df.rename(columns={\n",
    "        \"Open time\": \"entry_time\",\n",
    "        \"Close time\": \"exit_time\",\n",
    "        \"Instrument\": \"asset\",\n",
    "        \"Open price\": \"entry_price\",\n",
    "        \"Close price\": \"exit_price\",\n",
    "        \"Open volume\": \"position_size\",\n",
    "        \"PnL\": \"PnL\",\n",
    "        \"Profit (ticks)\": \"profit_ticks\",\n",
    "        \"Account\": \"account\"\n",
    "    })\n",
    "\n",
    "    trades_df[\"direction\"] = trades_df[\"position_size\"].apply(lambda x: \"Buy\" if x > 0 else \"Sell\")\n",
    "    trades_df[\"order_id_entry\"] = executions_df.iloc[::2][\"Exchange ID\"].values[:len(trades_df)]\n",
    "    trades_df[\"order_id_exit\"] = executions_df.iloc[1::2][\"Exchange ID\"].values[:len(trades_df)]\n",
    "\n",
    "    trades_df[\"source_file\"] = source_file\n",
    "    trades_df[\"commission\"] = executions_df[\"Commission\"].values[:2*len(trades_df)].reshape(-1, 2).sum(axis=1)\n",
    "    trades_df[\"PnL_net\"] = trades_df[\"PnL\"] - trades_df[\"commission\"]\n",
    "\n",
    "    trades_df[\"entry_time\"] = pd.to_datetime(trades_df[\"entry_time\"])\n",
    "    trades_df[\"exit_time\"] = pd.to_datetime(trades_df[\"exit_time\"])\n",
    "    trades_df[\"duration_minutes\"] = (trades_df[\"exit_time\"] - trades_df[\"entry_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "    equity_start = capital_base + trades_df[\"PnL\"].cumsum().iloc[0]\n",
    "    trades_df[\"equity\"] = equity_start + trades_df[\"PnL\"].cumsum()\n",
    "\n",
    "    return trades_df\n",
    "\n",
    "\n",
    "# database_io.py\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def save_to_postgres(trades_df, daily_stats, user=\"alex\", db=\"trading\"):\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{user}@localhost:5432/{db}\")\n",
    "    trades_df.to_sql(\"trades\", engine, if_exists=\"replace\", index=False)\n",
    "    daily_stats.to_sql(\"daily_summary\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "\n",
    "# validators.py\n",
    "def validate_required_columns(df, required):\n",
    "    missing = set(required) - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Faltan columnas requeridas: {missing}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda31b2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'excel_ingestion'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 133\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mequity_simulation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_equity_simulation\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m calcular_capital_actual\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexcel_ingestion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_excel_file\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprocess_trades\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_trade_dataframe, save_to_postgres\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'excel_ingestion'"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# config.py\n",
    "# =======================================\n",
    "\n",
    "CAPITAL_BASE_GLOBAL = 1000\n",
    "\n",
    "# =======================================\n",
    "# utils.py\n",
    "# =======================================\n",
    "\n",
    "import pandas as pd\n",
    "from config import CAPITAL_BASE_GLOBAL\n",
    "\n",
    "def calcular_capital_actual(df: pd.DataFrame) -> float:\n",
    "    if df.empty:\n",
    "        return CAPITAL_BASE_GLOBAL\n",
    "    if \"equity\" in df.columns and df[\"equity\"].iloc[-1] > 0:\n",
    "        return df[\"equity\"].iloc[-1]\n",
    "    return CAPITAL_BASE_GLOBAL + df[\"PnL\"].cumsum().iloc[-1] if 'PnL' in df.columns else CAPITAL_BASE_GLOBAL\n",
    "\n",
    "# =======================================\n",
    "# load_data.py\n",
    "# =======================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def load_existing_data(output_dir):\n",
    "    hist_path = output_dir / \"trades_hist.csv\"\n",
    "    sum_path = output_dir / \"trading_summary.csv\"\n",
    "\n",
    "    if hist_path.exists():\n",
    "        hist_df = pd.read_csv(hist_path)\n",
    "        if \"source_file\" not in hist_df.columns:\n",
    "            hist_df[\"source_file\"] = \"\"\n",
    "    else:\n",
    "        hist_df = pd.DataFrame()\n",
    "\n",
    "    if sum_path.exists():\n",
    "        summary_df = pd.read_csv(sum_path)\n",
    "        if \"source_file\" not in summary_df.columns:\n",
    "            summary_df[\"source_file\"] = \"\"\n",
    "    else:\n",
    "        summary_df = pd.DataFrame()\n",
    "\n",
    "    return hist_df, summary_df, hist_path, sum_path\n",
    "\n",
    "# =======================================\n",
    "# excel_ingestion.py\n",
    "# =======================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_excel_file(filepath: Path):\n",
    "    xls = pd.ExcelFile(filepath)\n",
    "    required_sheets = [\"Journal\", \"Executions\", \"Statistics\"]\n",
    "    for sheet in required_sheets:\n",
    "        if sheet not in xls.sheet_names:\n",
    "            raise ValueError(f\"El archivo {filepath.name} no contiene la hoja '{sheet}'\")\n",
    "    return {\n",
    "        \"source_file\": filepath.name,\n",
    "        \"journal\": pd.read_excel(xls, sheet_name=\"Journal\"),\n",
    "        \"executions\": pd.read_excel(xls, sheet_name=\"Executions\"),\n",
    "        \"statistics\": pd.read_excel(xls, sheet_name=\"Statistics\")\n",
    "    }\n",
    "\n",
    "# =======================================\n",
    "# process_trades.py\n",
    "# =======================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def build_trade_dataframe(journal_df, executions_df, source_file, capital_base=600):\n",
    "    n_trades = len(journal_df)\n",
    "    n_execs = len(executions_df)\n",
    "    if n_execs < 2:\n",
    "        raise ValueError(\"No hay suficientes ejecuciones.\")\n",
    "\n",
    "    max_trades = min(n_trades, n_execs // 2)\n",
    "    trades_df = journal_df.iloc[:max_trades].copy()\n",
    "\n",
    "    trades_df = trades_df.rename(columns={\n",
    "        \"Open time\": \"entry_time\",\n",
    "        \"Close time\": \"exit_time\",\n",
    "        \"Instrument\": \"asset\",\n",
    "        \"Open price\": \"entry_price\",\n",
    "        \"Close price\": \"exit_price\",\n",
    "        \"Open volume\": \"position_size\",\n",
    "        \"PnL\": \"PnL\",\n",
    "        \"Profit (ticks)\": \"profit_ticks\",\n",
    "        \"Account\": \"account\"\n",
    "    })\n",
    "\n",
    "    trades_df[\"direction\"] = trades_df[\"position_size\"].apply(lambda x: \"Buy\" if x > 0 else \"Sell\")\n",
    "    trades_df[\"order_id_entry\"] = executions_df.iloc[::2][\"Exchange ID\"].values[:len(trades_df)]\n",
    "    trades_df[\"order_id_exit\"] = executions_df.iloc[1::2][\"Exchange ID\"].values[:len(trades_df)]\n",
    "    trades_df[\"source_file\"] = source_file\n",
    "\n",
    "    raw_commissions = executions_df[\"Commission\"].values[:2 * len(trades_df)]\n",
    "    if len(raw_commissions) % 2 != 0:\n",
    "        raise ValueError(\"Comisiones mal formateadas\")\n",
    "    trades_df[\"commission\"] = raw_commissions.reshape(-1, 2).sum(axis=1)\n",
    "    trades_df[\"PnL_net\"] = trades_df[\"PnL\"] - trades_df[\"commission\"]\n",
    "\n",
    "    trades_df[\"entry_time\"] = pd.to_datetime(trades_df[\"entry_time\"])\n",
    "    trades_df[\"exit_time\"] = pd.to_datetime(trades_df[\"exit_time\"])\n",
    "    trades_df[\"duration_minutes\"] = (trades_df[\"exit_time\"] - trades_df[\"entry_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "    equity_start = capital_base + trades_df[\"PnL\"].cumsum().iloc[0]\n",
    "    trades_df[\"equity\"] = equity_start + trades_df[\"PnL\"].cumsum()\n",
    "\n",
    "    return trades_df\n",
    "\n",
    "def save_to_postgres(trades_df, daily_stats, user=\"alex\", db=\"trading\"):\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{user}@localhost:5432/{db}\")\n",
    "    trades_df.to_sql(\"trades\", engine, if_exists=\"replace\", index=False)\n",
    "    daily_stats.to_sql(\"daily_summary\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "# =======================================\n",
    "# main.py\n",
    "# =======================================\n",
    "\n",
    "from pathlib import Path\n",
    "from load_data import load_existing_data\n",
    "from bayesian_model import build_bayesian_params, bayesian_mc_simulation\n",
    "from streak_analysis import analyze_streaks\n",
    "from equity_simulation import plot_equity_simulation\n",
    "from utils import calcular_capital_actual\n",
    "from excel_ingestion import parse_excel_file\n",
    "from process_trades import build_trade_dataframe, save_to_postgres\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_dir = Path(\"input\")\n",
    "output_dir = Path(\"output\")\n",
    "input_dir.mkdir(exist_ok=True)\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "hist_df, summary_df, hist_path, sum_path = load_existing_data(output_dir)\n",
    "\n",
    "excel_files = sorted(input_dir.glob(\"*.xlsx\"), key=os.path.getmtime)\n",
    "\n",
    "for archivo in excel_files:\n",
    "    try:\n",
    "        data = parse_excel_file(archivo)\n",
    "        if data[\"source_file\"] in hist_df.get(\"source_file\", []).astype(str).values:\n",
    "            continue  # ya procesado\n",
    "\n",
    "        trades_df = build_trade_dataframe(data[\"journal\"], data[\"executions\"], data[\"source_file\"])\n",
    "        stats_df = data[\"statistics\"].set_index(\"Name\").T.reset_index(drop=True)\n",
    "        stats_df[\"source_file\"] = data[\"source_file\"]\n",
    "\n",
    "        hist_df = pd.concat([hist_df, trades_df], ignore_index=True)\n",
    "        hist_df.drop_duplicates(subset=[\"order_id_entry\", \"order_id_exit\"], inplace=True)\n",
    "        hist_df.to_csv(hist_path, index=False)\n",
    "\n",
    "        summary_df = pd.concat([summary_df, stats_df], ignore_index=True)\n",
    "        summary_df.to_csv(sum_path, index=False)\n",
    "\n",
    "        save_to_postgres(trades_df, stats_df)\n",
    "        print(f\"✅ Procesado: {archivo.name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error procesando {archivo.name}: {e}\")\n",
    "\n",
    "if hist_df.empty:\n",
    "    print(\"⚠️ No hay datos para analizar.\")\n",
    "else:\n",
    "    if 'PnL' not in hist_df.columns:\n",
    "        print(\"❌ Faltan columnas necesarias en el historial: 'PnL'\")\n",
    "    else:\n",
    "        params = build_bayesian_params(hist_df)\n",
    "        risk_of_ruin = bayesian_mc_simulation(params)\n",
    "        print(f\"\\n🔍 Riesgo de ruina estimado: {risk_of_ruin * 100:.2f}%\\n\")\n",
    "\n",
    "        win_rate_emp = (hist_df['PnL'] > 0).mean()\n",
    "        streak_df = analyze_streaks(win_rate_emp, len(hist_df))\n",
    "        print(streak_df.head())\n",
    "\n",
    "        plot_equity_simulation(\n",
    "            win_rate=55,\n",
    "            win_loss_ratio=2,\n",
    "            risk_per_trade=1,\n",
    "            n_trades=100,\n",
    "            n_lines=10,\n",
    "            trades_df=hist_df\n",
    "        )\n",
    "\n",
    "        print(\"✅ Análisis completo ejecutado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
