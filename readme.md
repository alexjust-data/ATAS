# üì¶ Setup cell for Jupyter notebooks

```python
# setup.py (o bien en la primera celda de cada notebook)
import sys
from pathlib import Path

# Ajusta seg√∫n la ubicaci√≥n del notebook respecto a la carpeta del proyecto
project_root = Path("..").resolve()  # sube un nivel si est√°s en /notebooks
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))
```

# Luego puedes hacer:

```python
from core import process_new_files, daily_summary_from_hist

# üì• Primera pasada sin fusi√≥n (para QA y debugging)
df_raw = process_new_files(merge_fragments=False, verbose=True)

# Forzamos inicializaci√≥n de columnas m√≠nimas si no hay merge:
if "components" not in df_raw.columns:
    df_raw["components"] = df_raw["trade_id"].apply(lambda x: [x])
    df_raw["n_components"] = 1
    df_raw["is_fragmented"] = False

# ‚úÖ Diagn√≥stico sin merge:
from core.qa import check_integrity
check_integrity(df_raw)

# üîÄ Luego puedes fusionar manualmente:
from core.merger import merge_split_trades
df = merge_split_trades(df_raw)

# üìä KPIs por d√≠a:
df_summary = daily_summary_from_hist(df)
df_summary.tail()
```

---

> ‚úÖ A√±ade esta celda en todos tus notebooks dentro de `/notebooks` para que Python encuentre `core/`.

---

## üìÅ Project Tree (estructura actual)

```text
RIESGO_PERDIDA/
‚îú‚îÄ‚îÄ core/                  # L√≥gica modular del sistema
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ capital.py         # Capital inicial (env, prompt, global)
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Paths, logging, variables globales
‚îÇ   ‚îú‚îÄ‚îÄ db_utils.py        # Reset y test de base de datos PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ fifo_loader.py     # Reconstrucci√≥n de trades FIFO desde Excel
‚îÇ   ‚îú‚îÄ‚îÄ io_utils.py        # Carga/guardado de CSV, SQL, Excel
‚îÇ   ‚îú‚îÄ‚îÄ merger.py          # Unifica trades fragmentados + explicaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py        # Orquesta el flujo completo de ingesta
‚îÇ   ‚îú‚îÄ‚îÄ summary.py         # KPIs diarios, winrate, profit factor
‚îÇ   ‚îî‚îÄ‚îÄ qa.py              # Quality Assurance: validaciones de integridad
‚îÇ
‚îú‚îÄ‚îÄ notebooks/            # Notebooks Jupyter para an√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ 00_overview.ipynb  # Gu√≠a general del proyecto y ejemplo de uso
‚îÇ   ‚îî‚îÄ‚îÄ ejemplo.ipynb
‚îÇ
‚îú‚îÄ‚îÄ input/                # Ficheros fuente (Excel .xlsx)
‚îú‚îÄ‚îÄ output/               # Resultados exportados (CSV, procesados)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

> Esta estructura permite importar cualquier funci√≥n de `core/` en los notebooks y mantener el c√≥digo limpio y reutilizable.

---

## ‚úÖ Chequeos de integridad sobre `df`

Estos chequeos se centralizan en `core/qa.py` ("Quality Assurance") para facilitar pruebas robustas. Ejemplo:

```python
from core.qa import check_integrity, debug_components

check_integrity(df)  # Lanza errores si encuentra incoherencias

# Tambi√©n puedes obtener un informe de errores:
report = check_integrity(df, return_report=True)
if report:
    print("Errores encontrados:", report)

# Diagn√≥stico visual de fragmentos con errores
from core.qa import debug_components
report = debug_components(df)
display(report)  # si est√°s en Jupyter Notebook
```

El archivo `qa.py` expone funciones robustas para validar:

| Test                        | Qu√© comprueba                                                     |
|----------------------------|-------------------------------------------------------------------|
| **IDs √∫nicos**             | No existan `trade_id` duplicados                                 |
| **Orden-IDs coherentes**   | Que `order_id_entry` y `order_id_exit` no est√©n duplicados       |
| **Vol√∫menes positivos**    | Que `position_size > 0`                                           |
| **Signo de PnL**           | Que el signo de `PnL` coincida con `PnL_net`                     |
| **Equity creciente**       | Que `equity = capital + PnL_net.cumsum()`                        |
| **Fragmentos consistentes**| Que los `components` coincidan con el `position_size` declarado  |

---

## ‚öôÔ∏è Nuevo par√°metro `verbose` en `process_new_files()`

Puedes activar mensajes informativos desde `core/pipeline.py` con:

```python
process_new_files(merge_fragments=False, verbose=True)
```

Esto:
- carga archivos .xlsx desde `input/`
- genera `df_raw` sin merge
- avisa si hay fragmentos (`is_fragmented=True`)
- **rellena autom√°ticamente** las columnas `components`, `n_components` y `is_fragmented` si faltan

Luego puedes fusionar manualmente y continuar con los an√°lisis. Esto te da control total para QA y depuraci√≥n.

---

## üß† Diagn√≥stico visual de trades fragmentados

Cuando `check_integrity()` lanza errores por componentes incoherentes, puedes usar:

```python
from core.qa import debug_components

# Obtiene un DataFrame con detalles de los trades conflictivos
debug_report = debug_components(df)
debug_report.sort_values("relative_error", ascending=False).head()
```

Esto muestra:
- `trade_id` del grupo fusionado
- `expected_sum`: suma esperada de componentes
- `declared_size`: tama√±o declarado en el merge
- `relative_error`: error porcentual
- `n_components`: cu√°ntos fragmentos lo componen

As√≠ puedes priorizar la depuraci√≥n de los casos m√°s graves. Despu√©s puedes inspeccionarlos visualmente con:

```python
from core.merger import explain_fragmented_trade

for tid in debug_report.sort_values("relative_error", ascending=False).head().trade_id:
    print("\n".join(explain_fragmented_trade(df, tid)))
    print("\n" + "-"*80 + "\n")
```

Esto imprime paso a paso las operaciones que forman cada trade fragmentado.

